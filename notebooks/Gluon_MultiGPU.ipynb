{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet.io import DataDesc\n",
    "from mxnet import nd, gluon, autograd\n",
    "from mxnet.gluon.data import RecordFileDataset, ArrayDataset\n",
    "from mxnet.gluon.data.vision.datasets import ImageRecordDataset\n",
    "from mxnet.gluon.data.dataloader import DataLoader\n",
    "from mxnet.gluon.model_zoo import vision as models\n",
    "from mxnet import recordio\n",
    "\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from common.utils import *\n",
    "from common.params_dense import *\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.4 |Anaconda custom (64-bit)| (default, Nov 20 2017, 18:44:38) \n",
      "[GCC 7.2.0]\n",
      "Numpy:  1.14.1\n",
      "MXNet:  1.3.0\n",
      "GPU:  ['Tesla V100-PCIE-16GB', 'Tesla V100-PCIE-16GB', 'Tesla V100-PCIE-16GB', 'Tesla V100-PCIE-16GB']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"MXNet: \", mx.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUs:  24\n",
      "GPUs:  4\n"
     ]
    }
   ],
   "source": [
    "CPU_COUNT = int(multiprocessing.cpu_count())\n",
    "GPU_COUNT = int(len(get_gpu_name()))\n",
    "MULTI_GPU = GPU_COUNT > 1\n",
    "print(\"CPUs: \", CPU_COUNT)\n",
    "print(\"GPUs: \", GPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually scale to multi-gpu\n",
    "if MULTI_GPU:\n",
    "    LR *= GPU_COUNT \n",
    "    BATCHSIZE *= GPU_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "TRAIN_LST = os.path.join(CSV_DEST, \"train.lst\")\n",
    "VALID_LST = os.path.join(CSV_DEST, \"valid.lst\")\n",
    "TEST_LST = os.path.join(CSV_DEST, \"test.lst\")\n",
    "TRAIN_REC = os.path.join(CSV_DEST, \"train.rec\")\n",
    "VALID_REC = os.path.join(CSV_DEST, \"valid.rec\")\n",
    "TEST_REC  = os.path.join(CSV_DEST, \"test.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 623 ms, sys: 233 ms, total: 856 ms\n",
      "Wall time: 855 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/_pytest/fixtures.py:844: DeprecationWarning: The `convert` argument is deprecated in favor of `converter`.  It will be removed after 2019/01.\n",
      "  params = attr.ib(convert=attr.converters.optional(tuple))\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/_pytest/fixtures.py:846: DeprecationWarning: The `convert` argument is deprecated in favor of `converter`.  It will be removed after 2019/01.\n",
      "  ids = attr.ib(default=None, convert=_ensure_immutable_ids)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "https://github.com/apache/incubator-mxnet/issues/1480\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "   Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0           58              M            PA                 2682     2749   \n",
       "1           58              M            PA                 2894     2729   \n",
       "2           58              M            PA                 2500     2048   \n",
       "3           81              M            PA                 2500     2048   \n",
       "4           81              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                        0.143  0.143          NaN  \n",
       "1                        0.143  0.143          NaN  \n",
       "2                        0.168  0.168          NaN  \n",
       "3                        0.171  0.171          NaN  \n",
       "4                        0.143  0.143          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LABEL_FILE)\n",
    "df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df, img_dir, patient_ids):\n",
    "    # Split labels on unfiltered data\n",
    "    df_label = df['Finding Labels'].str.split(\n",
    "        '|', expand=False).str.join(sep='*').str.get_dummies(sep='*')\n",
    "\n",
    "    # Filter by patient-ids (both)\n",
    "    df_label['Patient ID'] = df['Patient ID']\n",
    "    df_label = df_label[df_label['Patient ID'].isin(patient_ids)]\n",
    "    df = df[df['Patient ID'].isin(patient_ids)]\n",
    "    # Remove unncessary columns\n",
    "    df_label.drop(['Patient ID','No Finding'], axis=1, inplace=True)  \n",
    "\n",
    "    # List of images (full-path)\n",
    "    img_locs =  df['Image Index'].map(lambda im: os.path.join(img_dir, im)).values\n",
    "    # One-hot encoded labels (float32 for BCE loss)\n",
    "    df_label['Image_path'] = img_locs\n",
    "    return df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:21563 valid:3080 test:6162\n",
      "(87306, 15)\n",
      "(7616, 15)\n",
      "(17198, 15)\n"
     ]
    }
   ],
   "source": [
    "# Training / Valid / Test split (70% / 10% / 20%)\n",
    "train_set, valid_set, test_set = get_train_valid_test_split(TOT_PATIENT_NUMBER)\n",
    "df_train = data_prep(df, IMAGE_FOLDER, train_set)\n",
    "df_valid = data_prep(df, IMAGE_FOLDER, valid_set)\n",
    "df_test = data_prep(df, IMAGE_FOLDER, test_set)\n",
    "print(df_train.shape)\n",
    "print(df_valid.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(TRAIN_LST, sep='\\t', header=False)\n",
    "df_valid.to_csv(VALID_LST, sep='\\t', header=False)\n",
    "df_test.to_csv(TEST_LST, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PY_PATH = \"/anaconda/envs/py35/bin/python\"\n",
    "REC_PY = \"./common/im2rec.py\"\n",
    "if not os.path.isfile('chestxray/train.rec'):\n",
    "    subprocess.call([PY_PATH, REC_PY, \"chestxray/train.lst\", os.getcwd(), \n",
    "                     '--resize', '224', '--center-crop', '--quality', '100', '--num-thread', str(CPU_COUNT), '--pack-label'])\n",
    "    subprocess.call([PY_PATH, REC_PY, \"chestxray/valid.lst\", os.getcwd(), \n",
    "                     '--resize', '224', '--center-crop', '--quality', '100', '--num-thread', str(CPU_COUNT), '--pack-label'])\n",
    "    subprocess.call([PY_PATH, REC_PY, \"chestxray/test.lst\", os.getcwd(), \n",
    "                     '--resize', '224', '--center-crop', '--quality', '100', '--num-thread', str(CPU_COUNT), '--pack-label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "https://mxnet.incubator.apache.org/architecture/note_data_loading.html#mxnet-io-python-interface\n",
    "\n",
    "https://github.com/miraclewkf/multilabel-MXNet/blob/master/train_multilabel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing / Data Augmentation transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(image, label):\n",
    "    image = mx.image.resize_short(image, WIDTH)\n",
    "    image = image.astype(np.float32)/255.\n",
    "    image = mx.image.color_normalize(image,\n",
    "                                      mean=mx.nd.array(IMAGENET_RGB_MEAN),\n",
    "                                      std=mx.nd.array(IMAGENET_RGB_SD))\n",
    "    image = image.transpose((2,0,1))\n",
    "    return image, label\n",
    "        \n",
    "\n",
    "\n",
    "flipper = mx.image.HorizontalFlipAug(0.5)\n",
    "def transform_aug(image, label):\n",
    "    image = mx.image.resize_short(image, WIDTH+20)\n",
    "    image, crop_info = mx.image.random_crop(image, (WIDTH, HEIGHT))\n",
    "    image = image.astype(np.float32)/255.\n",
    "    image = mx.image.color_normalize(image,\n",
    "                                      mean=mx.nd.array(IMAGENET_RGB_MEAN, dtype=np.float32),\n",
    "                                      std=mx.nd.array(IMAGENET_RGB_SD, dtype=np.float32))\n",
    "    image = flipper(image)\n",
    "    image = image.transpose((2,0,1))\n",
    "    return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot fixing DataLoader for multi-processing and RecordFileDataset\n",
    "\n",
    "We hot-fix MXNet dataloaders to support multiprocessing with the ImageRecordDataSet.\n",
    "see this issue: https://github.com/apache/incubator-mxnet/issues/9974\n",
    "This is a hack and hasn't been tested thoroughly, use with caution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We keep the filename as an attribute\n",
    "# So that we can open a new handle per process\n",
    "# in the dataloader\n",
    "\n",
    "def __init__new(self, filename):\n",
    "    self._filename = filename\n",
    "    self.reinit()\n",
    "    \n",
    "def reinit(self):\n",
    "    idx_file = os.path.splitext(self._filename)[0] + '.idx'\n",
    "    self._record = mx.recordio.MXIndexedRecordIO(idx_file, self._filename, 'r')\n",
    "    \n",
    "RecordFileDataset.reinit = reinit\n",
    "RecordFileDataset.__init__ = __init__new\n",
    "\n",
    "# We modify the dataloader worker_loop to reinit the dataset if possible\n",
    "# And then call to the original worker_loop\n",
    "\n",
    "mx.gluon.data.dataloader.worker_loop_ = mx.gluon.data.dataloader.worker_loop\n",
    "\n",
    "def worker_loop(dataset, key_queue, data_queue, batchify_fn):\n",
    "    if 'reinit' in dir(dataset):\n",
    "        dataset.reinit()\n",
    "    mx.gluon.data.dataloader.worker_loop_(dataset, key_queue, data_queue, batchify_fn)\n",
    "\n",
    "mx.gluon.data.dataloader.worker_loop = worker_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageRecordDataset(TRAIN_REC, transform=transform_aug)\n",
    "val_dataset = ImageRecordDataset(VALID_REC, transform=transform_test)\n",
    "test_dataset = ImageRecordDataset(TEST_REC, transform=transform_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, BATCHSIZE, shuffle=True, num_workers=CPU_COUNT, last_batch='rollover')\n",
    "val_dataloader = DataLoader(val_dataset, BATCHSIZE, shuffle=False, num_workers=CPU_COUNT, last_batch='discard')\n",
    "test_dataloader = DataLoader(test_dataset, BATCHSIZE, shuffle=False, num_workers=CPU_COUNT, last_batch='discard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the symbols and weights of a pre-trained model and removing the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol():\n",
    "    get_mxnet_model('https://migonzastorage.blob.core.windows.net/deep-learning/models/mxnet/densenet-121', 0)\n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint('densenet-121', 0)\n",
    "    layer_name='pool5'\n",
    "    all_layers = sym.get_internals()\n",
    "    sym = all_layers[layer_name+'_output']\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params})\n",
    "    return sym, new_args, aux_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sym, arg_params, aux_params = get_symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = [mx.gpu(i) for i in range(GPU_COUNT)]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning pre-trained params to a Gluon Symbol block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained = gluon.nn.SymbolBlock(outputs=new_sym, inputs=mx.sym.var('data'))\n",
    "net_params = pre_trained.collect_params()\n",
    "for param in arg_params:\n",
    "    if param in net_params:\n",
    "        net_params[param]._load_init(arg_params[param], ctx=ctx)\n",
    "for param in aux_params:\n",
    "    if param in net_params:\n",
    "        net_params[param]._load_init(aux_params[param], ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new fully connected layer with CLASSES units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = gluon.nn.Dense(CLASSES)\n",
    "dense.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the new Gluon network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.HybridSequential()\n",
    "net.add(pre_trained)\n",
    "net.add(dense)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': LR})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = gluon.loss.SigmoidBinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = gluon.nn.Activation('sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = 0\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data_split = gluon.utils.split_and_load(data, ctx)\n",
    "        label_split = gluon.utils.split_and_load(label, ctx)\n",
    "        outputs = [(sig(net(X)),Y) for X, Y in zip(data_split, label_split)]\n",
    "        for output, label in outputs:\n",
    "            acc += float((label.asnumpy() == np.round(output.asnumpy())).sum()) / CLASSES / output.shape[0]\n",
    "    return acc/i/len(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[11:35:49] /home/travis/build/dmlc/mxnet-distro/mxnet-build/3rdparty/mshadow/mshadow/./stream_gpu-inl.h:62: Check failed: e == cudaSuccess CUDA: an illegal memory access was encountered\n\nStack trace returned 10 entries:\n[bt] (0) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x34d2fa) [0x7ff0678672fa]\n[bt] (1) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x34d921) [0x7ff067867921]\n[bt] (2) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2653c50) [0x7ff069b6dc50]\n[bt] (3) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x26c5a2a) [0x7ff069bdfa2a]\n[bt] (4) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2629529) [0x7ff069b43529]\n[bt] (5) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2632d24) [0x7ff069b4cd24]\n[bt] (6) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2636bc3) [0x7ff069b50bc3]\n[bt] (7) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2636e16) [0x7ff069b50e16]\n[bt] (8) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2633434) [0x7ff069b4d434]\n[bt] (9) /anaconda/envs/py35/bin/../lib/libstdc++.so.6(+0xafc5c) [0x7ff0b4361c5c]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1892\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [11:35:49] /home/travis/build/dmlc/mxnet-distro/mxnet-build/3rdparty/mshadow/mshadow/./stream_gpu-inl.h:62: Check failed: e == cudaSuccess CUDA: an illegal memory access was encountered\n\nStack trace returned 10 entries:\n[bt] (0) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x34d2fa) [0x7ff0678672fa]\n[bt] (1) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x34d921) [0x7ff067867921]\n[bt] (2) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2653c50) [0x7ff069b6dc50]\n[bt] (3) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x26c5a2a) [0x7ff069bdfa2a]\n[bt] (4) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2629529) [0x7ff069b43529]\n[bt] (5) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2632d24) [0x7ff069b4cd24]\n[bt] (6) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2636bc3) [0x7ff069b50bc3]\n[bt] (7) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2636e16) [0x7ff069b50e16]\n[bt] (8) /anaconda/envs/py35/lib/python3.5/site-packages/mxnet/libmxnet.so(+0x2633434) [0x7ff069b4d434]\n[bt] (9) /anaconda/envs/py35/bin/../lib/libstdc++.so.6(+0xafc5c) [0x7ff0b4361c5c]\n\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_batch = 50\n",
    "for e in range(EPOCHS):\n",
    "    tick = time()\n",
    "    for i, (data, label) in enumerate(train_dataloader):        \n",
    "        data_split = gluon.utils.split_and_load(data, ctx)\n",
    "        label_split = gluon.utils.split_and_load(label, ctx)  \n",
    "        \n",
    "        # Printing the loss here to allow data to be loaded asynchronously on the GPU\n",
    "        if (i%n_batch == 0 and i > 0):\n",
    "            print('Batch {0}: Sigmoid Binary Cross Entropy Loss: {1:.4f}'.format(i,sum(losses).mean().asscalar()))            \n",
    "            \n",
    "        with autograd.record():\n",
    "            losses = [binary_cross_entropy(net(X), Y) for X, Y in zip(data_split, label_split)]\n",
    "        for l in losses:\n",
    "            l.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "    test_accuracy = evaluate_accuracy(val_dataloader, net)\n",
    "    print('Epoch {0}, {1:.6f} test_accuracy after {2:.2f} seconds'.format(e, test_accuracy, time()-tick))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = np.zeros((0, CLASSES))\n",
    "labels = np.zeros((0, CLASSES))\n",
    "for (data, label) in (test_dataloader):        \n",
    "    data_split = gluon.utils.split_and_load(data, ctx)\n",
    "    label_split = gluon.utils.split_and_load(label, ctx)  \n",
    "    outputs = [sig(net(X)) for X in data_split]\n",
    "    predictions = np.concatenate([predictions, np.concatenate([output.asnumpy() for output in outputs])])\n",
    "    labels = np.concatenate([labels, np.concatenate([label.asnumpy() for label in label_split])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation AUC: {0:.4f}\".format(compute_roc_auc(labels, predictions, CLASSES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data (Pure Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Test on fake-data -> no IO lag\n",
    "batch_in_epoch = len(train_dataset)//BATCHSIZE\n",
    "tot_num = batch_in_epoch * BATCHSIZE\n",
    "fake_X = np.random.rand(tot_num, 3, 224, 224).astype(np.float32)\n",
    "fake_y = np.random.rand(tot_num, CLASSES).astype(np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_synth = ArrayDataset(fake_X, fake_y)\n",
    "train_dataloader_synth = DataLoader(train_dataset_synth, BATCHSIZE, shuffle=True, num_workers=CPU_COUNT, last_batch='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_batch = 50\n",
    "for e in range(EPOCHS):\n",
    "    tick = time()\n",
    "    for i, (data, label) in enumerate(train_dataloader_synth):        \n",
    "        data_split = gluon.utils.split_and_load(data, ctx)\n",
    "        label_split = gluon.utils.split_and_load(label, ctx)  \n",
    "        \n",
    "        # Printing the loss here to allow data to be loaded asynchronously on the GPU\n",
    "        if (i%n_batch == 0 and i > 0):\n",
    "            print('Batch {0}: Sigmoid Binary Cross Entropy Loss: {1:.4f}'.format(i,sum(losses).mean().asscalar()))            \n",
    "            \n",
    "        with autograd.record():\n",
    "            losses = [binary_cross_entropy(net(X), Y) for X, Y in zip(data_split, label_split)]\n",
    "        for l in losses:\n",
    "            l.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "    \n",
    "\n",
    "    print('Epoch {0}, {1:.2f} seconds, loss {2:.4f}'.format(e, time()-tick), sum(losses).mean().asscalar())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
